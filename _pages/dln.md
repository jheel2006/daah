---
permalink: /dln/
title: "Digital Literacy Narrative"
---

## Rethinking Digital Literacy: How My Understanding Evolved

As a 19-year-old student majoring in Computer Science and Interactive Media, I’ve always known that digital literacy plays a big role in my life. I spend most of my day online—coding, designing, researching, or simply communicating. But if you had asked me at the start of the semester what “digital literacy” meant, I probably would’ve said something like “being good at using technology” or “knowing how to search things up online.” I now realize that’s only a small part of the story.

Over the past few months, this course has changed the way I think about digital spaces, platforms, and tools. I’ve learned that digital literacy isn’t just about using tools well—it’s also about asking questions about how those tools work, what they leave out, and how they shape what we think is true or important. It’s about thinking critically, not just functionally.


---

### Platforms I Use and How I See Them Now


Right now, the platforms I use the most are ChatGPT, GitHub, Kepler, Figma, and VS Code. I use ChatGPT almost every day for brainstorming, quick explanations, and writing help. GitHub is where I collaborate on coding projects, and Kepler is something I’ve been experimenting with a lot recently as I try to better understand how to work with spatial data and visual storytelling. Figma is where I design UI/UX interfaces, and VS Code is my main environment for coding and debugging.

But my relationship with these platforms has shifted. Before, I mostly thought of them as tools—just things I use. Now, I pay more attention to how they work and what assumptions they make. For example, when I use AI tools like ChatGPT, I no longer assume the answers are always correct or neutral. These systems are built on huge datasets filled with human choices, patterns, and biases. As Johanna Drucker explains in *The Digital Humanities Coursebook*, digital knowledge isn’t neutral—it reflects the assumptions and structures built into the platforms (Drucker, Ch. 1). That idea really stuck with me. I now think more deeply about what’s behind a tool, not just what it gives me.


---

### Learning the Limits of Digital Tools

One of the biggest things I’ve realized is that every platform has both strengths and weaknesses. For example, GitHub is great for collaboration, but it assumes a certain technical literacy and language—people who aren't developers can easily feel excluded. Similarly, Kepler is a powerful tool for mapping and visualizing data, but its effectiveness still depends on what data you give it and how you frame the visualization. Even something like a search engine makes choices for me about what information I see first.

Understanding these “affordances and limitations” has helped me see that no digital tool is neutral or complete. There are always tradeoffs—who is included, what is prioritized, and what gets left out. When I work with data now, I try to be more mindful of what I’m seeing and what I might be missing.


---

### What I Was Good At—And What I’ve Learned

Coming into this course, I was already comfortable with coding, UI/UX design, and working in digital environments. I’ve built interactive art with p5.js, created web apps using React, and spent a lot of time iterating on design decisions. But what I hadn’t done enough of was stepping back to ask: what assumptions am I coding into this system? What stories are being told—or not told—through this interface?

That’s where I’ve grown the most. I’ve learned that being digitally literate means more than being able to build something—it’s about thinking critically while you build. Debbie Chachra’s essay *Why I Am Not a Maker* opened my eyes to the idea that care, maintenance, and reflection are just as important as making something new (Chachra, 2015). It made me feel seen—because sometimes I felt like my value was tied only to what I could create. Now I realize that asking the right questions, noticing patterns, and thinking ethically are equally valuable.

Berry and Fagerjord’s piece on *computational thinking* helped reinforce this idea. They talk about how computational thinking isn’t just a skill—it’s a mindset that involves abstraction, pattern recognition, and problem-solving through code, but also being able to question the systems we’re designing and using (Berry & Fagerjord, 2017). This framework helped me understand why technical work and critical thinking need to go hand in hand.


---

### Still Growing: What I Want to Improve

Even with everything I’ve learned, there are still areas where I want to improve. For one, I want to get better at understanding how data is structured and visualized. I’m fascinated by tools like Orange Data Mining and Voyant Tools, which we explored in class. They show how data can be shaped into patterns and insights—but also how those patterns can mislead if we’re not careful.

I also want to get more comfortable with critical frameworks from the humanities. As someone coming from a technical background, I still sometimes struggle with theoretical readings or historical lenses. But I’ve started to see how powerful those tools are for making sense of the digital world. They give me the language to talk about power, bias, and ethics in ways I didn’t have before.

---

### Working with AI: Cautious Curiosity

AI is a big part of how I work now, and I have mixed feelings about it. On one hand, tools like ChatGPT are incredibly helpful—they help me brainstorm ideas, rewrite code, or even reflect on projects like this one. But at the same time, I’m wary of over-relying on them.

Is GPT getting better at writing? In some ways, yes. It’s smoother, faster, and often sounds more natural. But better doesn’t always mean smarter. I’ve noticed that it can still be vague, repetitive, or miss important context. And most importantly, it still doesn’t *understand* what it’s saying—it just predicts based on patterns.

That’s why I now use AI more like a partner I’m always double-checking. I try to be aware of its limitations, question what it leaves out, and look for the human decisions behind its answers. AI is a tool—but I want to be the one steering the conversation, not the other way around.

---

### Thinking About Data in New Ways

Before this course, data felt like something static to me—just numbers in a table or lines on a graph. Now, I see it as something that’s always shaped by choices: what to collect, how to label, how to visualize. Working with tools like Orange and Kepler made this clear. For example, when I explored Kepler’s mapping features, I realized how easy it is to tell one kind of story with data and hide another.

In the same way, Fei-Fei Li’s TED Talk on computer vision showed how even advanced algorithms learn to see through patterns, labels, and massive training sets—not from true understanding. She explained how projects like ImageNet gave machines the ability to identify objects, but not to grasp deeper meaning or context (Li, n.d.). That idea stuck with me: data is not neutral, and machine perception is always shaped by what we feed it.

---

### Designing with Ethics in Mind

As an Interactive Media student, I care deeply about design. But this course has helped me think more about *ethical* design. Who gets to use this tool? Is it accessible to everyone? What happens to the data people share? How are algorithms shaping what people see?

In one of my recent projects, I created a generative art piece using randomness and algorithmic input. I realized midway that even randomness isn’t truly random—it’s shaped by the code I write. That project made me think harder about algorithmic bias, even in art. It reminded me that every design decision is also an ethical one.

---

### Moving Forward: A More Thoughtful Digital Practice

Looking ahead, I want to continue combining my technical skills with deeper critical thinking. I’m excited to keep working with creative tools, AI models, and interactive platforms. But I also want to keep asking hard questions: Who is this for? What voices are missing? What power dynamics are at play?

I hope to explore more in the digital humanities space, using tools like Voyant to analyze or present knowledge in more thoughtful ways. I want to stay open to learning from both tech and humanities—because both are essential for building a more ethical digital world.

---

### Final Thoughts

This class has expanded my idea of what it means to be digitally literate. It’s not just about being able to use technology—it’s about being aware of how it works, who it serves, and what it excludes. I’ve learned to see digital tools as shaped by people, politics, and power—not just as neutral systems.

I still have a lot to learn, but I feel more equipped now to use technology thoughtfully and responsibly. The readings by Johanna Drucker and Debbie Chachra helped shift my mindset, and exploring collaborative tools, AI systems, and data platforms gave me a more hands-on understanding of what digital literacy really involves.

I’m walking away from this course not just as someone who *uses* technology, but as someone who *thinks* about it—and that, to me, is the biggest takeaway of all.

---

### References

- Drucker, Johanna. *The Digital Humanities Coursebook: An Introduction to Digital Methods for Research and Scholarship*. Routledge, 2021. [Link](https://www.taylorfrancis.com/chapters/mono/10.4324/9781003106531-1/digital-humanities-overview-johanna-drucker?context=ubx&refId=d32fa15e-299e-4b0e-a0b7-496606198488)
- Chachra, Debbie. *Why I Am Not a Maker*. The Atlantic, 2015. [Link](https://www.theatlantic.com/technology/archive/2015/01/why-i-am-not-a-maker/384767/)
- Berry, D. M., & Fagerjord, A. (2017). *On the Way to Computational Thinking*. In *Digital Humanities: Knowledge and Critique in a Digital Age* (pp. 40–59).  
- Li, F. (n.d.). *How We Teach Computers to Understand Pictures*. TED Talk. [Link](https://www.youtube.com/watch?v=40riCqvRoMs)
